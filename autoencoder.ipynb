{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawled img links\n",
    "with open ('./jandan-links.txt', 'r') as f:\n",
    "    links = f.readlines()\n",
    "links = [x[:-1] for x in links]\n",
    "links = [x for x in links if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pre-process: resize, squarize, to_array\n",
    "import numpy as np\n",
    "import urllib\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "import http\n",
    "\n",
    "def url2img(url):\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url).read()\n",
    "        image = Image.open(BytesIO(response))\n",
    "        # use the first frame if gif\n",
    "        if '.gif' in url: \n",
    "            image.seek(0)\n",
    "        # make sure the image is in RGB mode\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert(mode='RGB')\n",
    "        # center crop\n",
    "        width, height = image.size\n",
    "        new    = min(width, height)\n",
    "        left   = (width - new) // 2\n",
    "        top    = (height - new) // 2\n",
    "        right  = (width + new) // 2\n",
    "        bottom = (height + new) // 2\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "        image = image.resize(size=(100,100))\n",
    "        # now convert the image to numpy array\n",
    "        array = np.array(image, dtype=np.float32)\n",
    "        return array\n",
    "    except http.client.IncompleteRead:\n",
    "        pass\n",
    "    except urllib.request.HTTPError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "img_bag = db.from_sequence(links[:5000])\n",
    "results = img_bag.map(url2img).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# implementation following notebook by mchablani\n",
    "# https://github.com/mchablani/deep-learning/blob/master/autoencoder/Convolutional_Autoencoder.ipynb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train = results[:4000]\n",
    "validation = results[4000:]\n",
    "\n",
    "learning_rate  = 0.01\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 100,100,3), name=\"input\")\n",
    "targets_ = tf.placeholder(tf.float32, (None, 100,100,3), name=\"target\")\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs=inputs_, filters=32, kernel_size=(20,20), padding='same', activation=tf.nn.relu)\n",
    "# Now 100 100 32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, pool_size=(5,5), strides=(5,5), padding='same')\n",
    "# Now 20 20 32\n",
    "conv2 = tf.layers.conv2d(inputs=maxpool1, filters=16, kernel_size=(5,5), padding='same', activation=tf.nn.relu)\n",
    "# Now 20 20 16\n",
    "encoded = tf.layers.max_pooling2d(conv2, pool_size=(5,5), strides=(4,4), padding='same')\n",
    "# Now 4 4 16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_images(encoded, size=(20,20), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 20 20 16\n",
    "conv4 = tf.layers.conv2d(inputs=upsample1, filters=16, kernel_size=(5,5), padding='same', activation=tf.nn.relu)\n",
    "# Now 20 20 16\n",
    "upsample2 = tf.image.resize_images(conv4, size=(100,100), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 100 100 16\n",
    "conv5 = tf.layers.conv2d(inputs=upsample2, filters=32, kernel_size=(20,20), padding='same', activation=tf.nn.relu)\n",
    "# Now 100 100 32\n",
    "\n",
    "logits = tf.layers.conv2d(inputs=conv5, filters=3, kernel_size=(20,20), padding='same', activation=None)\n",
    "#Now 100 100 3\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "#loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "loss = tf.losses.mean_squared_error(labels=targets_, predictions=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Training loss: 787.8068\n",
      "Epoch: 20/20... Training loss: 16638.5762\n",
      "Epoch: 20/20... Training loss: 15281.2607\n",
      "Epoch: 20/20... Training loss: 11036.9834\n",
      "Epoch: 20/20... Training loss: 8724.5225\n",
      "Epoch: 20/20... Training loss: 5771.9937\n",
      "Epoch: 20/20... Training loss: 12309.4482\n",
      "Epoch: 20/20... Training loss: 19170.9688\n",
      "Epoch: 20/20... Training loss: 1748.4464\n",
      "Epoch: 20/20... Training loss: 4451.9395\n",
      "Epoch: 20/20... Training loss: 19217.1836\n",
      "Epoch: 20/20... Training loss: 29467.1211\n",
      "Epoch: 20/20... Training loss: 7869.8579\n",
      "Epoch: 20/20... Training loss: 16660.3047\n",
      "Epoch: 20/20... Training loss: 3766.4622\n",
      "Epoch: 20/20... Training loss: 29394.5156\n",
      "Epoch: 20/20... Training loss: 22860.5117\n",
      "Epoch: 20/20... Training loss: 1229.4258\n",
      "Epoch: 20/20... Training loss: 8745.7393\n",
      "Epoch: 20/20... Training loss: 3552.6165\n",
      "Epoch: 20/20... Training loss: 6760.2114\n",
      "Epoch: 20/20... Training loss: 10170.0312\n",
      "Epoch: 20/20... Training loss: 3029.4277\n",
      "Epoch: 20/20... Training loss: 2708.9614\n",
      "Epoch: 20/20... Training loss: 4056.3010\n",
      "Epoch: 20/20... Training loss: 12552.2354\n",
      "Epoch: 20/20... Training loss: 6324.5991\n",
      "Epoch: 20/20... Training loss: 28463.9102\n",
      "Epoch: 20/20... Training loss: 15762.8057\n",
      "Epoch: 20/20... Training loss: 4809.7778\n",
      "Epoch: 20/20... Training loss: 6437.1650\n",
      "Epoch: 20/20... Training loss: 4006.1790\n",
      "Epoch: 20/20... Training loss: 4874.7607\n",
      "Epoch: 20/20... Training loss: 2760.5105\n",
      "Epoch: 20/20... Training loss: 5381.3726\n",
      "Epoch: 20/20... Training loss: 1490.5526\n",
      "Epoch: 20/20... Training loss: 11023.5068\n",
      "Epoch: 20/20... Training loss: 7229.8105\n",
      "Epoch: 20/20... Training loss: 13663.3193\n",
      "Epoch: 20/20... Training loss: 36167.0898\n",
      "Epoch: 20/20... Training loss: 37806.0898\n",
      "Epoch: 20/20... Training loss: 18301.9727\n",
      "Epoch: 20/20... Training loss: 4043.7434\n",
      "Epoch: 20/20... Training loss: 19621.5566\n",
      "Epoch: 20/20... Training loss: 17182.9805\n",
      "Epoch: 20/20... Training loss: 20852.8496\n",
      "Epoch: 20/20... Training loss: 10499.8125\n",
      "Epoch: 20/20... Training loss: 940.2895\n",
      "Epoch: 20/20... Training loss: 13785.2627\n",
      "Epoch: 20/20... Training loss: 969.3489\n",
      "Epoch: 20/20... Training loss: 5284.3979\n",
      "Epoch: 20/20... Training loss: 10246.0498\n",
      "Epoch: 20/20... Training loss: 5434.5513\n",
      "Epoch: 20/20... Training loss: 7395.6719\n",
      "Epoch: 20/20... Training loss: 11221.4375\n",
      "Epoch: 20/20... Training loss: 16804.8867\n",
      "Epoch: 20/20... Training loss: 28508.0566\n",
      "Epoch: 20/20... Training loss: 13219.8340\n",
      "Epoch: 20/20... Training loss: 6167.2002\n",
      "Epoch: 20/20... Training loss: 7345.9404\n",
      "Epoch: 20/20... Training loss: 16836.5918\n",
      "Epoch: 20/20... Training loss: 6759.7183\n",
      "Epoch: 20/20... Training loss: 10170.3809\n",
      "Epoch: 20/20... Training loss: 27233.1699\n",
      "Epoch: 20/20... Training loss: 8490.3740\n",
      "Epoch: 20/20... Training loss: 39086.6211\n",
      "Epoch: 20/20... Training loss: 1594.2362\n",
      "Epoch: 20/20... Training loss: 6522.7861\n",
      "Epoch: 20/20... Training loss: 8609.5537\n",
      "Epoch: 20/20... Training loss: 16547.5566\n",
      "Epoch: 20/20... Training loss: 2785.5542\n",
      "Epoch: 20/20... Training loss: 8437.5879\n",
      "Epoch: 20/20... Training loss: 7463.2891\n",
      "Epoch: 20/20... Training loss: 11876.4346\n",
      "Epoch: 20/20... Training loss: 11405.7002\n",
      "Epoch: 20/20... Training loss: 13271.6582\n",
      "Epoch: 20/20... Training loss: 30736.4688\n",
      "Epoch: 20/20... Training loss: 11006.8623\n",
      "Epoch: 20/20... Training loss: 4133.3979\n",
      "Epoch: 20/20... Training loss: 13735.0225\n",
      "Epoch: 20/20... Training loss: 11610.1670\n",
      "Epoch: 20/20... Training loss: 13924.3867\n",
      "Epoch: 20/20... Training loss: 11169.4814\n",
      "Epoch: 20/20... Training loss: 31458.3164\n",
      "Epoch: 20/20... Training loss: 8116.3140\n",
      "Epoch: 20/20... Training loss: 19054.1406\n",
      "Epoch: 20/20... Training loss: 5207.5991\n",
      "Epoch: 20/20... Training loss: 1440.0752\n",
      "Epoch: 20/20... Training loss: 11408.0088\n",
      "Epoch: 20/20... Training loss: 9390.0117\n",
      "Epoch: 20/20... Training loss: 6291.4175\n",
      "Epoch: 20/20... Training loss: 6896.0879\n",
      "Epoch: 20/20... Training loss: 7335.4697\n",
      "Epoch: 20/20... Training loss: 2432.0879\n",
      "Epoch: 20/20... Training loss: 35678.6250\n",
      "Epoch: 20/20... Training loss: 6817.1797\n",
      "Epoch: 20/20... Training loss: 13543.5479\n",
      "Epoch: 20/20... Training loss: 1655.0677\n",
      "Epoch: 20/20... Training loss: 7172.0107\n",
      "Epoch: 20/20... Training loss: 17447.8281\n",
      "Epoch: 20/20... Training loss: 8105.5073\n",
      "Epoch: 20/20... Training loss: 11493.1328\n",
      "Epoch: 20/20... Training loss: 8753.3984\n",
      "Epoch: 20/20... Training loss: 18282.7676\n",
      "Epoch: 20/20... Training loss: 35890.4219\n",
      "Epoch: 20/20... Training loss: 12093.5918\n",
      "Epoch: 20/20... Training loss: 2289.0364\n",
      "Epoch: 20/20... Training loss: 6295.9512\n",
      "Epoch: 20/20... Training loss: 31037.9688\n",
      "Epoch: 20/20... Training loss: 10977.7432\n",
      "Epoch: 20/20... Training loss: 7402.5532\n",
      "Epoch: 20/20... Training loss: 1326.2699\n",
      "Epoch: 20/20... Training loss: 31876.8457\n",
      "Epoch: 20/20... Training loss: 6863.8418\n",
      "Epoch: 20/20... Training loss: 21432.4199\n",
      "Epoch: 20/20... Training loss: 13689.3721\n",
      "Epoch: 20/20... Training loss: 40704.2930\n",
      "Epoch: 20/20... Training loss: 2080.2803\n",
      "Epoch: 20/20... Training loss: 9049.6758\n",
      "Epoch: 20/20... Training loss: 18054.5098\n",
      "Epoch: 20/20... Training loss: 9996.3438\n",
      "Epoch: 20/20... Training loss: 4711.5391\n",
      "Epoch: 20/20... Training loss: 31125.2617\n",
      "Epoch: 20/20... Training loss: 30361.7090\n",
      "Epoch: 20/20... Training loss: 5429.5220\n",
      "Epoch: 20/20... Training loss: 1831.5735\n",
      "Epoch: 20/20... Training loss: 28209.0234\n",
      "Epoch: 20/20... Training loss: 32907.0586\n",
      "Epoch: 20/20... Training loss: 20283.0293\n",
      "Epoch: 20/20... Training loss: 37009.5273\n",
      "Epoch: 20/20... Training loss: 9918.1953\n",
      "Epoch: 20/20... Training loss: 25218.2949\n",
      "Epoch: 20/20... Training loss: 7230.9438\n",
      "Epoch: 20/20... Training loss: 34412.9375\n",
      "Epoch: 20/20... Training loss: 7174.1948\n",
      "Epoch: 20/20... Training loss: 32454.9844\n",
      "Epoch: 20/20... Training loss: 16783.2051\n",
      "Epoch: 20/20... Training loss: 5489.6655\n",
      "Epoch: 20/20... Training loss: 1982.8325\n",
      "Epoch: 20/20... Training loss: 22610.7188\n",
      "Epoch: 20/20... Training loss: 1495.5702\n",
      "Epoch: 20/20... Training loss: 11663.2793\n",
      "Epoch: 20/20... Training loss: 10847.4980\n",
      "Epoch: 20/20... Training loss: 13596.7793\n",
      "Epoch: 20/20... Training loss: 1161.6589\n",
      "Epoch: 20/20... Training loss: 18510.8867\n",
      "Epoch: 20/20... Training loss: 6367.7163\n",
      "Epoch: 20/20... Training loss: 13170.1953\n",
      "Epoch: 20/20... Training loss: 26160.4180\n",
      "Epoch: 20/20... Training loss: 27436.9883\n",
      "Epoch: 20/20... Training loss: 38329.7578\n",
      "Epoch: 20/20... Training loss: 40661.5234\n",
      "Epoch: 20/20... Training loss: 5448.6284\n",
      "Epoch: 20/20... Training loss: 22297.5176\n",
      "Epoch: 20/20... Training loss: 31778.2227\n",
      "Epoch: 20/20... Training loss: 1017.1455\n",
      "Epoch: 20/20... Training loss: 4212.8066\n",
      "Epoch: 20/20... Training loss: 6328.3115\n",
      "Epoch: 20/20... Training loss: 7347.1606\n",
      "Epoch: 20/20... Training loss: 8047.4785\n",
      "Epoch: 20/20... Training loss: 7632.8892\n",
      "Epoch: 20/20... Training loss: 37620.8281\n",
      "Epoch: 20/20... Training loss: 7683.1650\n",
      "Epoch: 20/20... Training loss: 5260.3906\n",
      "Epoch: 20/20... Training loss: 13736.4229\n",
      "Epoch: 20/20... Training loss: 6497.6577\n",
      "Epoch: 20/20... Training loss: 36545.7148\n",
      "Epoch: 20/20... Training loss: 12870.8457\n",
      "Epoch: 20/20... Training loss: 21350.8047\n",
      "Epoch: 20/20... Training loss: 39535.9102\n",
      "Epoch: 20/20... Training loss: 7765.5830\n",
      "Epoch: 20/20... Training loss: 3927.4673\n",
      "Epoch: 20/20... Training loss: 17584.0449\n",
      "Epoch: 20/20... Training loss: 8011.5552\n",
      "Epoch: 20/20... Training loss: 6269.7666\n",
      "Epoch: 20/20... Training loss: 7980.3286\n",
      "Epoch: 20/20... Training loss: 5076.1411\n",
      "Epoch: 20/20... Training loss: 19954.7930\n",
      "Epoch: 20/20... Training loss: 18253.2305\n",
      "Epoch: 20/20... Training loss: 26777.1699\n",
      "Epoch: 20/20... Training loss: 5544.8735\n",
      "Epoch: 20/20... Training loss: 29763.6016\n",
      "Epoch: 20/20... Training loss: 12686.8203\n",
      "Epoch: 20/20... Training loss: 36705.8164\n",
      "Epoch: 20/20... Training loss: 6269.5479\n",
      "Epoch: 20/20... Training loss: 4424.3989\n",
      "Epoch: 20/20... Training loss: 8010.4644\n",
      "Epoch: 20/20... Training loss: 4380.3193\n",
      "Epoch: 20/20... Training loss: 9496.9346\n",
      "Epoch: 20/20... Training loss: 29431.2285\n",
      "Epoch: 20/20... Training loss: 10773.5254\n",
      "Epoch: 20/20... Training loss: 2478.8518\n",
      "Epoch: 20/20... Training loss: 3546.0239\n",
      "Epoch: 20/20... Training loss: 8895.5420\n",
      "Epoch: 20/20... Training loss: 5228.6401\n",
      "Epoch: 20/20... Training loss: 30251.1543\n",
      "Epoch: 20/20... Training loss: 4089.0007\n",
      "Epoch: 20/20... Training loss: 12256.1289\n",
      "Epoch: 20/20... Training loss: 11119.6416\n",
      "Epoch: 20/20... Training loss: 23520.3008\n",
      "Epoch: 20/20... Training loss: 3167.9685\n",
      "Epoch: 20/20... Training loss: 12671.2803\n",
      "Epoch: 20/20... Training loss: 5589.0669\n",
      "Epoch: 20/20... Training loss: 1634.3613\n",
      "Epoch: 20/20... Training loss: 1771.8105\n",
      "Epoch: 20/20... Training loss: 17514.3906\n",
      "Epoch: 20/20... Training loss: 15294.1885\n",
      "Epoch: 20/20... Training loss: 7257.9902\n",
      "Epoch: 20/20... Training loss: 6913.4741\n",
      "Epoch: 20/20... Training loss: 3383.8733\n",
      "Epoch: 20/20... Training loss: 9486.5322\n",
      "Epoch: 20/20... Training loss: 6156.8203\n",
      "Epoch: 20/20... Training loss: 11175.6416\n",
      "Epoch: 20/20... Training loss: 10386.2529\n",
      "Epoch: 20/20... Training loss: 10554.4727\n",
      "Epoch: 20/20... Training loss: 6433.0977\n",
      "Epoch: 20/20... Training loss: 15316.8828\n",
      "Epoch: 20/20... Training loss: 6611.0508\n",
      "Epoch: 20/20... Training loss: 8429.6006\n",
      "Epoch: 20/20... Training loss: 2529.5493\n",
      "Epoch: 20/20... Training loss: 18046.9453\n",
      "Epoch: 20/20... Training loss: 12316.2578\n",
      "Epoch: 20/20... Training loss: 38891.0352\n",
      "Epoch: 20/20... Training loss: 17169.7832\n",
      "Epoch: 20/20... Training loss: 10253.9336\n",
      "Epoch: 20/20... Training loss: 5587.2095\n",
      "Epoch: 20/20... Training loss: 37249.2969\n",
      "Epoch: 20/20... Training loss: 8043.4048\n",
      "Epoch: 20/20... Training loss: 38070.1680\n",
      "Epoch: 20/20... Training loss: 10837.5713\n",
      "Epoch: 20/20... Training loss: 19583.2109\n",
      "Epoch: 20/20... Training loss: 9717.4824\n",
      "Epoch: 20/20... Training loss: 7119.9858\n",
      "Epoch: 20/20... Training loss: 12250.3711\n",
      "Epoch: 20/20... Training loss: 6063.2070\n",
      "Epoch: 20/20... Training loss: 16423.1816\n",
      "Epoch: 20/20... Training loss: 8578.5859\n",
      "Epoch: 20/20... Training loss: 37330.4062\n",
      "Epoch: 20/20... Training loss: 5956.9692\n",
      "Epoch: 20/20... Training loss: 10328.6123\n",
      "Epoch: 20/20... Training loss: 32469.6504\n",
      "Epoch: 20/20... Training loss: 13312.9922\n",
      "Epoch: 20/20... Training loss: 6078.9790\n",
      "Epoch: 20/20... Training loss: 8471.3613\n",
      "Epoch: 20/20... Training loss: 9413.2715\n",
      "Epoch: 20/20... Training loss: 24932.6191\n",
      "Epoch: 20/20... Training loss: 41003.9453\n",
      "Epoch: 20/20... Training loss: 1808.1031\n",
      "Epoch: 20/20... Training loss: 11230.3105\n",
      "Epoch: 20/20... Training loss: 6565.2798\n",
      "Epoch: 20/20... Training loss: 6636.8413\n",
      "Epoch: 20/20... Training loss: 2980.7246\n",
      "Epoch: 20/20... Training loss: 32604.9277\n",
      "Epoch: 20/20... Training loss: 5836.7817\n",
      "Epoch: 20/20... Training loss: 32723.5352\n",
      "Epoch: 20/20... Training loss: 35146.6562\n",
      "Epoch: 20/20... Training loss: 35910.3867\n",
      "Epoch: 20/20... Training loss: 6689.5791\n",
      "Epoch: 20/20... Training loss: 8789.0977\n",
      "Epoch: 20/20... Training loss: 760.2852\n",
      "Epoch: 20/20... Training loss: 7429.9170\n",
      "Epoch: 20/20... Training loss: 6067.6885\n",
      "Epoch: 20/20... Training loss: 10592.0918\n",
      "Epoch: 20/20... Training loss: 13867.7441\n",
      "Epoch: 20/20... Training loss: 23915.8477\n",
      "Epoch: 20/20... Training loss: 29752.5117\n",
      "Epoch: 20/20... Training loss: 18145.7188\n",
      "Epoch: 20/20... Training loss: 1575.6200\n",
      "Epoch: 20/20... Training loss: 4590.7456\n",
      "Epoch: 20/20... Training loss: 7402.7148\n",
      "Epoch: 20/20... Training loss: 6779.4878\n",
      "Epoch: 20/20... Training loss: 11352.1631\n",
      "Epoch: 20/20... Training loss: 1036.7838\n",
      "Epoch: 20/20... Training loss: 34651.0000\n",
      "Epoch: 20/20... Training loss: 3240.3274\n",
      "Epoch: 20/20... Training loss: 2990.0947\n",
      "Epoch: 20/20... Training loss: 31104.7344\n",
      "Epoch: 20/20... Training loss: 19976.0547\n",
      "Epoch: 20/20... Training loss: 14503.2383\n",
      "Epoch: 20/20... Training loss: 3131.4614\n",
      "Epoch: 20/20... Training loss: 25466.1504\n",
      "Epoch: 20/20... Training loss: 9840.0664\n",
      "Epoch: 20/20... Training loss: 4542.2642\n",
      "Epoch: 20/20... Training loss: 7138.6797\n",
      "Epoch: 20/20... Training loss: 7572.0513\n",
      "Epoch: 20/20... Training loss: 12547.8740\n",
      "Epoch: 20/20... Training loss: 11977.8770\n",
      "Epoch: 20/20... Training loss: 11467.8701\n",
      "Epoch: 20/20... Training loss: 11900.4688\n",
      "Epoch: 20/20... Training loss: 7308.0063\n",
      "Epoch: 20/20... Training loss: 10888.1387\n",
      "Epoch: 20/20... Training loss: 10490.5361\n",
      "Epoch: 20/20... Training loss: 24104.4531\n",
      "Epoch: 20/20... Training loss: 7137.2983\n",
      "Epoch: 20/20... Training loss: 32170.7578\n",
      "Epoch: 20/20... Training loss: 8660.9492\n",
      "Epoch: 20/20... Training loss: 4528.2354\n",
      "Epoch: 20/20... Training loss: 11553.0498\n",
      "Epoch: 20/20... Training loss: 7512.5381\n",
      "Epoch: 20/20... Training loss: 7759.1196\n",
      "Epoch: 20/20... Training loss: 2799.3999\n",
      "Epoch: 20/20... Training loss: 33136.2891\n",
      "Epoch: 20/20... Training loss: 10449.8848\n",
      "Epoch: 20/20... Training loss: 10121.6514\n",
      "Epoch: 20/20... Training loss: 12880.4844\n",
      "Epoch: 20/20... Training loss: 9334.8223\n",
      "Epoch: 20/20... Training loss: 9408.4287\n",
      "Epoch: 20/20... Training loss: 8467.1377\n",
      "Epoch: 20/20... Training loss: 17770.5859\n",
      "Epoch: 20/20... Training loss: 12919.5996\n",
      "Epoch: 20/20... Training loss: 3035.2080\n",
      "Epoch: 20/20... Training loss: 6121.0967\n",
      "Epoch: 20/20... Training loss: 11110.8584\n",
      "Epoch: 20/20... Training loss: 6767.4585\n",
      "Epoch: 20/20... Training loss: 5120.5601\n",
      "Epoch: 20/20... Training loss: 18283.4961\n",
      "Epoch: 20/20... Training loss: 6561.5469\n",
      "Epoch: 20/20... Training loss: 4536.2539\n",
      "Epoch: 20/20... Training loss: 7086.7554\n",
      "Epoch: 20/20... Training loss: 5800.8696\n",
      "Epoch: 20/20... Training loss: 6603.5596\n",
      "Epoch: 20/20... Training loss: 8304.2510\n",
      "Epoch: 20/20... Training loss: 38136.9297\n",
      "Epoch: 20/20... Training loss: 26533.1758\n",
      "Epoch: 20/20... Training loss: 32067.5410\n",
      "Epoch: 20/20... Training loss: 38241.8633\n",
      "Epoch: 20/20... Training loss: 17429.3652\n",
      "Epoch: 20/20... Training loss: 10929.8770\n",
      "Epoch: 20/20... Training loss: 10527.8232\n",
      "Epoch: 20/20... Training loss: 39559.4727\n",
      "Epoch: 20/20... Training loss: 14783.4980\n",
      "Epoch: 20/20... Training loss: 29900.6777\n",
      "Epoch: 20/20... Training loss: 32189.3965\n",
      "Epoch: 20/20... Training loss: 33455.3203\n",
      "Epoch: 20/20... Training loss: 1733.1702\n",
      "Epoch: 20/20... Training loss: 15537.2725\n",
      "Epoch: 20/20... Training loss: 24720.7676\n",
      "Epoch: 20/20... Training loss: 5875.7124\n",
      "Epoch: 20/20... Training loss: 12788.3350\n",
      "Epoch: 20/20... Training loss: 8414.7471\n",
      "Epoch: 20/20... Training loss: 25358.1523\n",
      "Epoch: 20/20... Training loss: 39353.6914\n",
      "Epoch: 20/20... Training loss: 34375.0469\n",
      "Epoch: 20/20... Training loss: 3871.7510\n",
      "Epoch: 20/20... Training loss: 2188.0212\n",
      "Epoch: 20/20... Training loss: 13199.6865\n",
      "Epoch: 20/20... Training loss: 31249.7930\n",
      "Epoch: 20/20... Training loss: 6472.8364\n",
      "Epoch: 20/20... Training loss: 5025.2705\n",
      "Epoch: 20/20... Training loss: 5001.7539\n",
      "Epoch: 20/20... Training loss: 11197.9502\n",
      "Epoch: 20/20... Training loss: 12499.0732\n",
      "Epoch: 20/20... Training loss: 34399.8633\n",
      "Epoch: 20/20... Training loss: 17135.2871\n",
      "Epoch: 20/20... Training loss: 5207.8252\n",
      "Epoch: 20/20... Training loss: 11819.8594\n",
      "Epoch: 20/20... Training loss: 9939.0840\n",
      "Epoch: 20/20... Training loss: 15177.8496\n",
      "Epoch: 20/20... Training loss: 4004.5408\n",
      "Epoch: 20/20... Training loss: 6301.7026\n",
      "Epoch: 20/20... Training loss: 3585.1582\n",
      "Epoch: 20/20... Training loss: 9319.0068\n",
      "Epoch: 20/20... Training loss: 9945.0146\n",
      "Epoch: 20/20... Training loss: 37900.8008\n",
      "Epoch: 20/20... Training loss: 13203.3955\n",
      "Epoch: 20/20... Training loss: 1033.5651\n",
      "Epoch: 20/20... Training loss: 11363.2559\n",
      "Epoch: 20/20... Training loss: 11911.4795\n",
      "Epoch: 20/20... Training loss: 8523.6797\n",
      "Epoch: 20/20... Training loss: 25612.4727\n",
      "Epoch: 20/20... Training loss: 29018.5566\n",
      "Epoch: 20/20... Training loss: 5567.8271\n",
      "Epoch: 20/20... Training loss: 6357.1587\n",
      "Epoch: 20/20... Training loss: 15581.2754\n",
      "Epoch: 20/20... Training loss: 15669.6807\n",
      "Epoch: 20/20... Training loss: 7310.7305\n",
      "Epoch: 20/20... Training loss: 14553.2676\n",
      "Epoch: 20/20... Training loss: 9569.2842\n",
      "Epoch: 20/20... Training loss: 2642.6230\n",
      "Epoch: 20/20... Training loss: 13478.7168\n",
      "Epoch: 20/20... Training loss: 12267.3135\n",
      "Epoch: 20/20... Training loss: 14037.4844\n",
      "Epoch: 20/20... Training loss: 26548.7578\n",
      "Epoch: 20/20... Training loss: 31490.5977\n",
      "Epoch: 20/20... Training loss: 3615.7871\n",
      "Epoch: 20/20... Training loss: 11746.7695\n",
      "Epoch: 20/20... Training loss: 10082.9863\n",
      "Epoch: 20/20... Training loss: 10590.5830\n",
      "Epoch: 20/20... Training loss: 6500.3804\n",
      "Epoch: 20/20... Training loss: 17759.9336\n",
      "Epoch: 20/20... Training loss: 13980.7207\n",
      "Epoch: 20/20... Training loss: 28583.4629\n",
      "Epoch: 20/20... Training loss: 30540.9453\n",
      "Epoch: 20/20... Training loss: 13086.5234\n",
      "Epoch: 20/20... Training loss: 3330.3904\n",
      "Epoch: 20/20... Training loss: 38233.3750\n",
      "Epoch: 20/20... Training loss: 6392.2534\n",
      "Epoch: 20/20... Training loss: 9306.4258\n",
      "Epoch: 20/20... Training loss: 1262.2456\n",
      "Epoch: 20/20... Training loss: 9235.0498\n",
      "Epoch: 20/20... Training loss: 1655.8412\n",
      "Epoch: 20/20... Training loss: 22815.7559\n",
      "Epoch: 20/20... Training loss: 2539.4124\n",
      "Epoch: 20/20... Training loss: 2149.3691\n",
      "Epoch: 20/20... Training loss: 10545.9453\n",
      "Epoch: 20/20... Training loss: 22184.6309\n",
      "Epoch: 20/20... Training loss: 2105.0015\n",
      "Epoch: 20/20... Training loss: 21047.3066\n",
      "Epoch: 20/20... Training loss: 19146.4707\n",
      "Epoch: 20/20... Training loss: 29928.2910\n",
      "Epoch: 20/20... Training loss: 28853.0391\n",
      "Epoch: 20/20... Training loss: 7764.0352\n",
      "Epoch: 20/20... Training loss: 28764.7070\n",
      "Epoch: 20/20... Training loss: 13582.0420\n",
      "Epoch: 20/20... Training loss: 2497.6694\n",
      "Epoch: 20/20... Training loss: 9626.7002\n",
      "Epoch: 20/20... Training loss: 5591.5532\n",
      "Epoch: 20/20... Training loss: 21452.2090\n",
      "Epoch: 20/20... Training loss: 10463.5312\n",
      "Epoch: 20/20... Training loss: 9732.9414\n",
      "Epoch: 20/20... Training loss: 6463.5317\n",
      "Epoch: 20/20... Training loss: 15738.7178\n",
      "Epoch: 20/20... Training loss: 20948.0254\n",
      "Epoch: 20/20... Training loss: 11314.1523\n",
      "Epoch: 20/20... Training loss: 37801.4219\n",
      "Epoch: 20/20... Training loss: 5228.0425\n",
      "Epoch: 20/20... Training loss: 12314.9287\n",
      "Epoch: 20/20... Training loss: 9244.2754\n",
      "Epoch: 20/20... Training loss: 13557.2930\n",
      "Epoch: 20/20... Training loss: 3177.5884\n",
      "Epoch: 20/20... Training loss: 20717.2773\n",
      "Epoch: 20/20... Training loss: 8920.4805\n",
      "Epoch: 20/20... Training loss: 3047.9319\n",
      "Epoch: 20/20... Training loss: 9856.0449\n",
      "Epoch: 20/20... Training loss: 13098.7646\n",
      "Epoch: 20/20... Training loss: 29314.8164\n",
      "Epoch: 20/20... Training loss: 18613.7422\n",
      "Epoch: 20/20... Training loss: 6625.5723\n",
      "Epoch: 20/20... Training loss: 16751.5781\n",
      "Epoch: 20/20... Training loss: 8393.0713\n",
      "Epoch: 20/20... Training loss: 7883.6309\n",
      "Epoch: 20/20... Training loss: 11729.1777\n",
      "Epoch: 20/20... Training loss: 16032.7451\n",
      "Epoch: 20/20... Training loss: 16686.0078\n",
      "Epoch: 20/20... Training loss: 6488.7373\n",
      "Epoch: 20/20... Training loss: 9800.9102\n",
      "Epoch: 20/20... Training loss: 38139.5156\n",
      "Epoch: 20/20... Training loss: 5146.5439\n",
      "Epoch: 20/20... Training loss: 1952.3315\n",
      "Epoch: 20/20... Training loss: 4143.8438\n",
      "Epoch: 20/20... Training loss: 10655.0508\n",
      "Epoch: 20/20... Training loss: 11365.8535\n",
      "Epoch: 20/20... Training loss: 40977.1133\n",
      "Epoch: 20/20... Training loss: 3769.5669\n",
      "Epoch: 20/20... Training loss: 10878.8096\n",
      "Epoch: 20/20... Training loss: 9614.3359\n",
      "Epoch: 20/20... Training loss: 21647.2422\n",
      "Epoch: 20/20... Training loss: 29630.9766\n",
      "Epoch: 20/20... Training loss: 34268.4688\n",
      "Epoch: 20/20... Training loss: 14642.2217\n",
      "Epoch: 20/20... Training loss: 9428.7812\n",
      "Epoch: 20/20... Training loss: 7056.6489\n",
      "Epoch: 20/20... Training loss: 7650.9893\n",
      "Epoch: 20/20... Training loss: 6010.4663\n",
      "Epoch: 20/20... Training loss: 35836.5430\n",
      "Epoch: 20/20... Training loss: 38002.4453\n",
      "Epoch: 20/20... Training loss: 6186.7339\n",
      "Epoch: 20/20... Training loss: 10561.2822\n",
      "Epoch: 20/20... Training loss: 22815.3379\n",
      "Epoch: 20/20... Training loss: 34752.4492\n",
      "Epoch: 20/20... Training loss: 5099.9038\n",
      "Epoch: 20/20... Training loss: 5018.8687\n",
      "Epoch: 20/20... Training loss: 7842.7319\n",
      "Epoch: 20/20... Training loss: 18389.7363\n",
      "Epoch: 20/20... Training loss: 8181.7114\n",
      "Epoch: 20/20... Training loss: 9171.1484\n",
      "Epoch: 20/20... Training loss: 15604.3672\n",
      "Epoch: 20/20... Training loss: 9832.9199\n",
      "Epoch: 20/20... Training loss: 6144.9707\n",
      "Epoch: 20/20... Training loss: 6410.4907\n",
      "Epoch: 20/20... Training loss: 11651.3213\n",
      "Epoch: 20/20... Training loss: 11244.2393\n",
      "Epoch: 20/20... Training loss: 3667.5835\n",
      "Epoch: 20/20... Training loss: 31235.6660\n",
      "Epoch: 20/20... Training loss: 5229.0903\n",
      "Epoch: 20/20... Training loss: 35668.8477\n",
      "Epoch: 20/20... Training loss: 3395.9338\n",
      "Epoch: 20/20... Training loss: 39255.0664\n",
      "Epoch: 20/20... Training loss: 6728.1807\n",
      "Epoch: 20/20... Training loss: 4995.5649\n",
      "Epoch: 20/20... Training loss: 14056.5674\n",
      "Epoch: 20/20... Training loss: 11509.6006\n",
      "Epoch: 20/20... Training loss: 4752.8140\n",
      "Epoch: 20/20... Training loss: 3181.2627\n",
      "Epoch: 20/20... Training loss: 40290.1836\n",
      "Epoch: 20/20... Training loss: 34887.3086\n",
      "Epoch: 20/20... Training loss: 33347.3008\n",
      "Epoch: 20/20... Training loss: 2320.6348\n",
      "Epoch: 20/20... Training loss: 8449.3682\n",
      "Epoch: 20/20... Training loss: 6975.6128\n",
      "Epoch: 20/20... Training loss: 7565.5034\n",
      "Epoch: 20/20... Training loss: 5653.5151\n",
      "Epoch: 20/20... Training loss: 3552.1428\n",
      "Epoch: 20/20... Training loss: 2948.0513\n",
      "Epoch: 20/20... Training loss: 4556.9673\n",
      "Epoch: 20/20... Training loss: 12722.1992\n",
      "Epoch: 20/20... Training loss: 7484.9194\n",
      "Epoch: 20/20... Training loss: 35767.2109\n",
      "Epoch: 20/20... Training loss: 8946.8691\n",
      "Epoch: 20/20... Training loss: 17179.1133\n",
      "Epoch: 20/20... Training loss: 2976.4583\n",
      "Epoch: 20/20... Training loss: 27840.4395\n",
      "Epoch: 20/20... Training loss: 14185.2354\n",
      "Epoch: 20/20... Training loss: 15633.3545\n",
      "Epoch: 20/20... Training loss: 19548.0156\n",
      "Epoch: 20/20... Training loss: 6841.4780\n",
      "Epoch: 20/20... Training loss: 8030.1382\n",
      "Epoch: 20/20... Training loss: 6578.0967\n",
      "Epoch: 20/20... Training loss: 16978.4004\n",
      "Epoch: 20/20... Training loss: 33786.7422\n",
      "Epoch: 20/20... Training loss: 7557.5317\n",
      "Epoch: 20/20... Training loss: 15587.0166\n",
      "Epoch: 20/20... Training loss: 11193.5977\n",
      "Epoch: 20/20... Training loss: 11353.1836\n",
      "Epoch: 20/20... Training loss: 32067.5977\n",
      "Epoch: 20/20... Training loss: 12402.0479\n",
      "Epoch: 20/20... Training loss: 11140.2578\n",
      "Epoch: 20/20... Training loss: 11613.4668\n",
      "Epoch: 20/20... Training loss: 36038.7227\n",
      "Epoch: 20/20... Training loss: 14801.9736\n",
      "Epoch: 20/20... Training loss: 5678.0439\n",
      "Epoch: 20/20... Training loss: 3202.7253\n",
      "Epoch: 20/20... Training loss: 14190.2871\n",
      "Epoch: 20/20... Training loss: 5623.6230\n",
      "Epoch: 20/20... Training loss: 2190.1755\n",
      "Epoch: 20/20... Training loss: 8681.4180\n",
      "Epoch: 20/20... Training loss: 10736.1377\n",
      "Epoch: 20/20... Training loss: 23932.6094\n",
      "Epoch: 20/20... Training loss: 6183.3975\n",
      "Epoch: 20/20... Training loss: 7757.5732\n",
      "Epoch: 20/20... Training loss: 8036.2617\n",
      "Epoch: 20/20... Training loss: 8804.7539\n",
      "Epoch: 20/20... Training loss: 6429.3940\n",
      "Epoch: 20/20... Training loss: 3948.8296\n",
      "Epoch: 20/20... Training loss: 11929.8711\n",
      "Epoch: 20/20... Training loss: 9573.5469\n",
      "Epoch: 20/20... Training loss: 6973.7236\n",
      "Epoch: 20/20... Training loss: 11203.2217\n",
      "Epoch: 20/20... Training loss: 3616.4844\n",
      "Epoch: 20/20... Training loss: 4300.1978\n",
      "Epoch: 20/20... Training loss: 11519.3555\n",
      "Epoch: 20/20... Training loss: 11060.1768\n",
      "Epoch: 20/20... Training loss: 2655.2917\n",
      "Epoch: 20/20... Training loss: 1179.3655\n",
      "Epoch: 20/20... Training loss: 22874.9883\n",
      "Epoch: 20/20... Training loss: 37773.0117\n",
      "Epoch: 20/20... Training loss: 4846.8511\n",
      "Epoch: 20/20... Training loss: 24291.4980\n",
      "Epoch: 20/20... Training loss: 2433.4480\n",
      "Epoch: 20/20... Training loss: 6907.8428\n",
      "Epoch: 20/20... Training loss: 6460.6582\n",
      "Epoch: 20/20... Training loss: 9915.9951\n",
      "Epoch: 20/20... Training loss: 36494.5703\n",
      "Epoch: 20/20... Training loss: 5478.8320\n",
      "Epoch: 20/20... Training loss: 6814.4155\n",
      "Epoch: 20/20... Training loss: 33333.3164\n",
      "Epoch: 20/20... Training loss: 5805.5415\n",
      "Epoch: 20/20... Training loss: 9865.7031\n",
      "Epoch: 20/20... Training loss: 3214.5427\n",
      "Epoch: 20/20... Training loss: 1299.3994\n",
      "Epoch: 20/20... Training loss: 29767.1387\n",
      "Epoch: 20/20... Training loss: 20283.9961\n",
      "Epoch: 20/20... Training loss: 6757.6011\n",
      "Epoch: 20/20... Training loss: 9243.3877\n",
      "Epoch: 20/20... Training loss: 10780.2109\n",
      "Epoch: 20/20... Training loss: 25190.6621\n",
      "Epoch: 20/20... Training loss: 32685.6328\n",
      "Epoch: 20/20... Training loss: 18719.6953\n",
      "Epoch: 20/20... Training loss: 30101.4766\n",
      "Epoch: 20/20... Training loss: 30939.5586\n",
      "Epoch: 20/20... Training loss: 14127.6689\n",
      "Epoch: 20/20... Training loss: 6429.7720\n",
      "Epoch: 20/20... Training loss: 13497.9258\n",
      "Epoch: 20/20... Training loss: 17623.6367\n",
      "Epoch: 20/20... Training loss: 6295.1157\n",
      "Epoch: 20/20... Training loss: 11764.4121\n",
      "Epoch: 20/20... Training loss: 10063.7109\n",
      "Epoch: 20/20... Training loss: 5539.4604\n",
      "Epoch: 20/20... Training loss: 2491.7756\n",
      "Epoch: 20/20... Training loss: 5805.9224\n",
      "Epoch: 20/20... Training loss: 7380.5210\n",
      "Epoch: 20/20... Training loss: 7841.2725\n",
      "Epoch: 20/20... Training loss: 5897.7476\n",
      "Epoch: 20/20... Training loss: 2353.1824\n",
      "Epoch: 20/20... Training loss: 9088.8721\n",
      "Epoch: 20/20... Training loss: 9872.9854\n",
      "Epoch: 20/20... Training loss: 5997.4209\n",
      "Epoch: 20/20... Training loss: 4268.6172\n",
      "Epoch: 20/20... Training loss: 16830.1328\n",
      "Epoch: 20/20... Training loss: 1591.3132\n",
      "Epoch: 20/20... Training loss: 28828.6328\n",
      "Epoch: 20/20... Training loss: 6624.5674\n",
      "Epoch: 20/20... Training loss: 2532.4827\n",
      "Epoch: 20/20... Training loss: 36748.4727\n",
      "Epoch: 20/20... Training loss: 19304.3203\n",
      "Epoch: 20/20... Training loss: 5597.4355\n",
      "Epoch: 20/20... Training loss: 11095.3389\n",
      "Epoch: 20/20... Training loss: 37699.2422\n",
      "Epoch: 20/20... Training loss: 17832.1367\n",
      "Epoch: 20/20... Training loss: 5441.0244\n",
      "Epoch: 20/20... Training loss: 4074.3389\n",
      "Epoch: 20/20... Training loss: 3055.1924\n",
      "Epoch: 20/20... Training loss: 3952.9207\n",
      "Epoch: 20/20... Training loss: 28505.5664\n",
      "Epoch: 20/20... Training loss: 27213.1973\n",
      "Epoch: 20/20... Training loss: 29284.0488\n",
      "Epoch: 20/20... Training loss: 37744.9219\n",
      "Epoch: 20/20... Training loss: 14988.9482\n",
      "Epoch: 20/20... Training loss: 12821.1406\n",
      "Epoch: 20/20... Training loss: 9659.0400\n",
      "Epoch: 20/20... Training loss: 8013.1748\n",
      "Epoch: 20/20... Training loss: 9934.0439\n",
      "Epoch: 20/20... Training loss: 3171.5120\n",
      "Epoch: 20/20... Training loss: 9164.9971\n",
      "Epoch: 20/20... Training loss: 6399.6816\n",
      "Epoch: 20/20... Training loss: 8805.9092\n",
      "Epoch: 20/20... Training loss: 9677.2334\n",
      "Epoch: 20/20... Training loss: 14421.6611\n",
      "Epoch: 20/20... Training loss: 4072.2341\n",
      "Epoch: 20/20... Training loss: 13947.5410\n",
      "Epoch: 20/20... Training loss: 16438.6973\n",
      "Epoch: 20/20... Training loss: 27231.3262\n",
      "Epoch: 20/20... Training loss: 31116.4336\n",
      "Epoch: 20/20... Training loss: 6390.9873\n",
      "Epoch: 20/20... Training loss: 5191.8223\n",
      "Epoch: 20/20... Training loss: 10235.1758\n",
      "Epoch: 20/20... Training loss: 8424.1914\n",
      "Epoch: 20/20... Training loss: 14806.8945\n",
      "Epoch: 20/20... Training loss: 12167.0225\n",
      "Epoch: 20/20... Training loss: 15604.0381\n",
      "Epoch: 20/20... Training loss: 25574.5957\n",
      "Epoch: 20/20... Training loss: 12842.2402\n",
      "Epoch: 20/20... Training loss: 7127.4302\n",
      "Epoch: 20/20... Training loss: 4374.9023\n",
      "Epoch: 20/20... Training loss: 4681.0698\n",
      "Epoch: 20/20... Training loss: 36052.2969\n",
      "Epoch: 20/20... Training loss: 34325.8750\n",
      "Epoch: 20/20... Training loss: 7718.3540\n",
      "Epoch: 20/20... Training loss: 24037.7344\n",
      "Epoch: 20/20... Training loss: 32664.1914\n",
      "Epoch: 20/20... Training loss: 7237.5352\n",
      "Epoch: 20/20... Training loss: 6873.5552\n",
      "Epoch: 20/20... Training loss: 6670.1924\n",
      "Epoch: 20/20... Training loss: 38223.8047\n",
      "Epoch: 20/20... Training loss: 7810.2646\n",
      "Epoch: 20/20... Training loss: 8887.2510\n",
      "Epoch: 20/20... Training loss: 2889.9106\n",
      "Epoch: 20/20... Training loss: 10869.6318\n",
      "Epoch: 20/20... Training loss: 9343.6719\n",
      "Epoch: 20/20... Training loss: 14563.4863\n",
      "Epoch: 20/20... Training loss: 11917.3330\n",
      "Epoch: 20/20... Training loss: 10899.7129\n",
      "Epoch: 20/20... Training loss: 18734.1465\n",
      "Epoch: 20/20... Training loss: 4875.5308\n",
      "Epoch: 20/20... Training loss: 4132.5161\n",
      "Epoch: 20/20... Training loss: 8179.4541\n",
      "Epoch: 20/20... Training loss: 9216.8086\n",
      "Epoch: 20/20... Training loss: 3328.5276\n",
      "Epoch: 20/20... Training loss: 9165.7217\n",
      "Epoch: 20/20... Training loss: 15269.9551\n",
      "Epoch: 20/20... Training loss: 5776.6860\n",
      "Epoch: 20/20... Training loss: 18333.0781\n",
      "Epoch: 20/20... Training loss: 2693.3364\n",
      "Epoch: 20/20... Training loss: 11926.7783\n",
      "Epoch: 20/20... Training loss: 5582.9243\n",
      "Epoch: 20/20... Training loss: 3240.5701\n",
      "Epoch: 20/20... Training loss: 24847.9023\n",
      "Epoch: 20/20... Training loss: 10972.0811\n",
      "Epoch: 20/20... Training loss: 11927.0205\n",
      "Epoch: 20/20... Training loss: 5740.9604\n",
      "Epoch: 20/20... Training loss: 14126.9990\n",
      "Epoch: 20/20... Training loss: 7233.3159\n",
      "Epoch: 20/20... Training loss: 17798.2012\n",
      "Epoch: 20/20... Training loss: 17184.0410\n",
      "Epoch: 20/20... Training loss: 6984.6484\n",
      "Epoch: 20/20... Training loss: 12329.6611\n",
      "Epoch: 20/20... Training loss: 23767.4277\n",
      "Epoch: 20/20... Training loss: 36044.9531\n",
      "Epoch: 20/20... Training loss: 12112.3604\n",
      "Epoch: 20/20... Training loss: 7289.1772\n",
      "Epoch: 20/20... Training loss: 17086.5312\n",
      "Epoch: 20/20... Training loss: 12112.5801\n",
      "Epoch: 20/20... Training loss: 7729.4390\n",
      "Epoch: 20/20... Training loss: 37178.8633\n",
      "Epoch: 20/20... Training loss: 432.9887\n",
      "Epoch: 20/20... Training loss: 23075.4766\n",
      "Epoch: 20/20... Training loss: 38974.5391\n",
      "Epoch: 20/20... Training loss: 32252.3652\n",
      "Epoch: 20/20... Training loss: 9988.9561\n",
      "Epoch: 20/20... Training loss: 12029.8770\n",
      "Epoch: 20/20... Training loss: 7379.6226\n",
      "Epoch: 20/20... Training loss: 4309.5532\n",
      "Epoch: 20/20... Training loss: 36369.4414\n",
      "Epoch: 20/20... Training loss: 10612.9697\n",
      "Epoch: 20/20... Training loss: 11004.3936\n",
      "Epoch: 20/20... Training loss: 6991.3745\n",
      "Epoch: 20/20... Training loss: 7546.2485\n",
      "Epoch: 20/20... Training loss: 6014.8564\n",
      "Epoch: 20/20... Training loss: 10498.9229\n",
      "Epoch: 20/20... Training loss: 4600.3018\n",
      "Epoch: 20/20... Training loss: 6541.0972\n",
      "Epoch: 20/20... Training loss: 20418.2266\n",
      "Epoch: 20/20... Training loss: 13935.5498\n",
      "Epoch: 20/20... Training loss: 3180.2314\n",
      "Epoch: 20/20... Training loss: 6880.7529\n",
      "Epoch: 20/20... Training loss: 12760.2725\n",
      "Epoch: 20/20... Training loss: 780.2941\n",
      "Epoch: 20/20... Training loss: 36440.7383\n",
      "Epoch: 20/20... Training loss: 17162.3418\n",
      "Epoch: 20/20... Training loss: 9752.9639\n",
      "Epoch: 20/20... Training loss: 17183.5508\n",
      "Epoch: 20/20... Training loss: 4245.7007\n",
      "Epoch: 20/20... Training loss: 24133.8535\n",
      "Epoch: 20/20... Training loss: 7008.9185\n",
      "Epoch: 20/20... Training loss: 8267.6455\n",
      "Epoch: 20/20... Training loss: 7638.3198\n",
      "Epoch: 20/20... Training loss: 2541.3486\n",
      "Epoch: 20/20... Training loss: 2833.4714\n",
      "Epoch: 20/20... Training loss: 6990.7031\n",
      "Epoch: 20/20... Training loss: 8170.1602\n",
      "Epoch: 20/20... Training loss: 12860.2627\n",
      "Epoch: 20/20... Training loss: 20742.0449\n",
      "Epoch: 20/20... Training loss: 13131.9912\n",
      "Epoch: 20/20... Training loss: 21086.5566\n",
      "Epoch: 20/20... Training loss: 13598.6904\n",
      "Epoch: 20/20... Training loss: 14762.4922\n",
      "Epoch: 20/20... Training loss: 4335.6943\n",
      "Epoch: 20/20... Training loss: 13274.9229\n",
      "Epoch: 20/20... Training loss: 38807.8711\n",
      "Epoch: 20/20... Training loss: 24489.0664\n",
      "Epoch: 20/20... Training loss: 8479.4014\n",
      "Epoch: 20/20... Training loss: 12630.2783\n",
      "Epoch: 20/20... Training loss: 6455.5933\n",
      "Epoch: 20/20... Training loss: 32003.8145\n",
      "Epoch: 20/20... Training loss: 8810.9785\n",
      "Epoch: 20/20... Training loss: 11262.2812\n",
      "Epoch: 20/20... Training loss: 11838.3174\n",
      "Epoch: 20/20... Training loss: 9006.8887\n",
      "Epoch: 20/20... Training loss: 38712.1484\n",
      "Epoch: 20/20... Training loss: 11636.1836\n",
      "Epoch: 20/20... Training loss: 8352.4453\n",
      "Epoch: 20/20... Training loss: 11976.7012\n",
      "Epoch: 20/20... Training loss: 8285.7490\n",
      "Epoch: 20/20... Training loss: 16348.6738\n",
      "Epoch: 20/20... Training loss: 12459.7207\n",
      "Epoch: 20/20... Training loss: 11819.0957\n",
      "Epoch: 20/20... Training loss: 2726.3704\n",
      "Epoch: 20/20... Training loss: 17907.8359\n",
      "Epoch: 20/20... Training loss: 36499.4297\n",
      "Epoch: 20/20... Training loss: 1645.3534\n",
      "Epoch: 20/20... Training loss: 3013.7664\n",
      "Epoch: 20/20... Training loss: 26873.3320\n",
      "Epoch: 20/20... Training loss: 14197.7100\n",
      "Epoch: 20/20... Training loss: 32565.9355\n",
      "Epoch: 20/20... Training loss: 3232.5396\n",
      "Epoch: 20/20... Training loss: 2959.0510\n",
      "Epoch: 20/20... Training loss: 13099.5586\n",
      "Epoch: 20/20... Training loss: 2978.8303\n",
      "Epoch: 20/20... Training loss: 1784.4982\n",
      "Epoch: 20/20... Training loss: 10308.4434\n",
      "Epoch: 20/20... Training loss: 26782.0801\n",
      "Epoch: 20/20... Training loss: 6489.6309\n",
      "Epoch: 20/20... Training loss: 5464.5586\n",
      "Epoch: 20/20... Training loss: 11937.6006\n",
      "Epoch: 20/20... Training loss: 8365.9971\n",
      "Epoch: 20/20... Training loss: 5535.9146\n",
      "Epoch: 20/20... Training loss: 14181.8867\n",
      "Epoch: 20/20... Training loss: 4264.0581\n",
      "Epoch: 20/20... Training loss: 15057.0107\n",
      "Epoch: 20/20... Training loss: 2811.1631\n",
      "Epoch: 20/20... Training loss: 22230.2812\n",
      "Epoch: 20/20... Training loss: 12791.5068\n",
      "Epoch: 20/20... Training loss: 4715.5469\n",
      "Epoch: 20/20... Training loss: 23490.9414\n",
      "Epoch: 20/20... Training loss: 3740.8289\n",
      "Epoch: 20/20... Training loss: 3812.7158\n",
      "Epoch: 20/20... Training loss: 9293.9688\n",
      "Epoch: 20/20... Training loss: 4555.1733\n",
      "Epoch: 20/20... Training loss: 12800.9473\n",
      "Epoch: 20/20... Training loss: 7970.1133\n",
      "Epoch: 20/20... Training loss: 36386.7188\n",
      "Epoch: 20/20... Training loss: 5059.8535\n",
      "Epoch: 20/20... Training loss: 3987.0986\n",
      "Epoch: 20/20... Training loss: 29322.7480\n",
      "Epoch: 20/20... Training loss: 1636.3883\n",
      "Epoch: 20/20... Training loss: 10082.2910\n",
      "Epoch: 20/20... Training loss: 10003.5879\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 5\n",
    "session.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(len(train)//batch_size - 1):\n",
    "        batch = train[batch_size*ii: batch_size*(ii+1)]\n",
    "        try:\n",
    "            imgs = batch[0].reshape((-1, 100, 100, 3))\n",
    "        except AttributeError: \n",
    "            continue\n",
    "        batch_cost, _ = session.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "        if e == 19:\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_img = np.array(validation[:10])\n",
    "reconstructed = session.run(decoded, feed_dict={inputs_: in_img.reshape((10, 100, 100, 3))})\n",
    "\n",
    "for images, row in zip([in_img, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((100, 100, 3)), cmap='jet')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
